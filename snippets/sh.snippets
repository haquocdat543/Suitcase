snippet ukubectl "Kubectl Ubuntu" b
sudo apt update
sudo apt install curl
curl -LO https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
kubectl version --client

$1
endsnippet

snippet uk8s "K8s ubuntu" b
sudo apt-get update 

sudo apt-get install -y docker.io
sudo usermod –aG docker Ubuntu
newgrp docker
sudo chmod 777 /var/run/docker.sock

sudo curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

sudo tee /etc/apt/sources.list.d/kubernetes.list <<EOF
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF

sudo apt-get update

sudo apt-get install -y kubelet kubeadm kubectl

sudo snap install kube-apiserver

$1
endsnippet

snippet umk8s "Ubuntu master k8s" b
sudo kubeadm init --pod-network-cidr=10.244.0.0/16
# in case your in root exit from it and run below commands
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

$1
endsnippet

snippet uprome "Ubuntu Prometheus" b
# Prometheus
sudo useradd \
    --system \
    --no-create-home \
    --shell /bin/false prometheus
wget https://github.com/prometheus/prometheus/releases/download/v2.47.1/prometheus-2.47.1.linux-amd64.tar.gz
tar -xvf prometheus-2.47.1.linux-amd64.tar.gz
sudo mkdir -p /data /etc/prometheus
cd prometheus-2.47.1.linux-amd64/
sudo mv prometheus promtool /usr/local/bin/
udo mv consoles/ console_libraries/ /etc/prometheus/
sudo mv prometheus.yml /etc/prometheus/prometheus.yml
sudo chown -R prometheus:prometheus /etc/prometheus/ /data/
cd
rm -rf prometheus-2.47.1.linux-amd64.tar.gz
prometheus --version

cat << EOF | sudo tee -a /etc/systemd/system/prometheus.service
[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target

StartLimitIntervalSec=500
StartLimitBurst=5

[Service]
User=prometheus
Group=prometheus
Type=simple
Restart=on-failure
RestartSec=5s
ExecStart=/usr/local/bin/prometheus \
  --config.file=/etc/prometheus/prometheus.yml \
  --storage.tsdb.path=/data \
  --web.console.templates=/etc/prometheus/consoles \
  --web.console.libraries=/etc/prometheus/console_libraries \
  --web.listen-address=0.0.0.0:9090 \
  --web.enable-lifecycle

[Install]
WantedBy=multi-user.target
EOF
sudo systemctl enable prometheus
sudo systemctl start prometheus

$1
endsnippet

snippet ugra "Ubuntu Grafana" b
# Grafana
sudo apt-get install -y apt-transport-https software-properties-common
wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -
echo "deb https://packages.grafana.com/oss/deb stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list
sudo apt-get update -y
sudo apt-get -y install grafana
sudo systemctl enable grafana-server
sudo systemctl start grafana-server

$1
endsnippet

snippet unex "Ubuntu Node_exporter" 
# Node Exporter
sudo useradd \
    --system \
    --no-create-home \
    --shell /bin/false node_exporter
wget https://github.com/prometheus/node_exporter/releases/download/v1.6.1/node_exporter-1.6.1.linux-amd64.tar.gz
tar -xvf node_exporter-1.6.1.linux-amd64.tar.gz
sudo mv \
  node_exporter-1.6.1.linux-amd64/node_exporter \
  /usr/local/bin/
rm -rf node_exporter*
cat << EOF | sudo tee -a /etc/systemd/system/node_exporter.service
[Unit]
Description=Node Exporter
Wants=network-online.target
After=network-online.target

StartLimitIntervalSec=500
StartLimitBurst=5

[Service]
User=node_exporter
Group=node_exporter
Type=simple
Restart=on-failure
RestartSec=5s
ExecStart=/usr/local/bin/node_exporter \
    --collector.logind

[Install]
WantedBy=multi-user.target

EOF
sudo systemctl enable node_exporter
sudo systemctl start node_exporter

cat << EOF | sudo tee -a /etc/prometheus/prometheus.yml
  - job_name: node_export
    static_configs:
          - targets: ["localhost:9100"]
EOF
promtool check config /etc/prometheus/prometheus.yml
curl -X POST http://localhost:9090/-/reload

$1
endsnippet

snippet cenjk "Centos jenkins" b
sudo yum update –y
sudo wget -O /etc/yum.repos.d/jenkins.repo \
    https://pkg.jenkins.io/redhat-stable/jenkins.repo
sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key
sudo yum upgrade -y
sudo dnf install java-17-amazon-corretto -y
sudo yum install jenkins -y
sudo systemctl enable jenkins
sudo systemctl start jenkins
endsnippet

snippet ujk "Test" b
# Install Openjdk and Jenkins
sudo apt update -y
sudo apt install fontconfig openjdk-17-jre -y
curl -fsSL https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key | sudo tee /usr/share/keyrings/jenkins-keyring.asc > /dev/null
echo deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] https://pkg.jenkins.io/debian-stable binary/ | sudo tee /etc/apt/sources.list.d/jenkins.list > /dev/null
sudo apt-get update -y
sudo apt-get install jenkins -y
sudo systemctl start jenkins

$1
endsnippet

snippet ujava "Ubuntu Java" b
# Install Java
sudo apt update -y
wget -O - https://packages.adoptium.net/artifactory/api/gpg/key/public | tee /etc/apt/keyrings/adoptium.asc
echo "deb [signed-by=/etc/apt/keyrings/adoptium.asc] https://packages.adoptium.net/artifactory/deb $(awk -F= '/^VERSION_CODENAME/{print$2}' /etc/os-release) main" | tee /etc/apt/sources.list.d/adoptium.list
sudo apt update -y
sudo apt install temurin-17-jdk -y

$1
endsnippet

snippet utv "Ubuntu Trivy" b
# install trivy
sudo apt-get install wget apt-transport-https gnupg lsb-release -y
wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | gpg --dearmor | sudo tee /usr/share/keyrings/trivy.gpg > /dev/null
echo "deb [signed-by=/usr/share/keyrings/trivy.gpg] https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
sudo apt-get update
sudo apt-get install trivy -y

$1
endsnippet

snippet udk "Ubuntu Docker" b
# Install Docker
sudo apt-get update
sudo apt-get install docker.io -y
sudo usermod -aG docker ubuntu
newgrp docker
sudo chmod 777 /var/run/docker.sock

$1
endsnippet

snippet udksonar "Ubuntu Sonarqube on Docker" b
# Install Docker and Sonarqube
sudo apt-get update
sudo apt-get install docker.io -y
sudo usermod -aG docker ubuntu
newgrp docker
sudo chmod 777 /var/run/docker.sock
docker run -d --name sonar -p 9000:9000 sonarqube:lts-community

$1
endsnippet

snippet urbmq "Ubuntu rabbitmq" b
sudo apt-get update -y
sudo apt-get install -y rabbitmq-server
sudo systemctl enable rabbitmq-server
sudo systemctl start rabbitmq-server
endsnippet

snippet udkrbmq "Ubuntu Rabbitmq on Docker" b
# Install Docker and Rabbitmq
sudo apt-get update
sudo apt-get install docker.io -y
sudo usermod -aG docker ubuntu
newgrp docker
sudo chmod 777 /var/run/docker.sock
docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3.12-management

$1
endsnippet

snippet var "Variable" b
${1:CONTAINERD_VERSION}="${2:1.7.3}"
endsnippet

snippet s1 "Sed type 1" b
sudo sed -i 's/${1:firstString}/${2:secondString}/g' ${3:Path}
endsnippet

snippet s2 "Sed type 2" b
sed -i "1s/^/${1:String}/" ${2:Path}
endsnippet

snippet s3 "Sed type 3" b
sudo sed '/^${1:String}/d' ${2:Path}
endsnippet

snippet s4 "Sed type 4" b
cat << EOF | sudo tee -a ${1:Path}
${2:Content}
EOF
endsnippet

snippet s5 "Sed type 5" b
sed '/${1:Strint}/,$d' ${2:Path}
endsnippet

snippet hn "Set hostname" b
hostnamectl set-hostname ${1:Sonarqube}
endsnippet

snippet ex "Export" b
export ${1:VER}="${2:0.40.2}"
endsnippet

snippet helm "Script for helm operation" b
#!/bin/bash

OPTION=\${1}

# OPTION="--dry-run --debug"
# VALUE_PATH="values-override.yaml" 
VALUE_PATH="values.yaml" 
RELEASE_NAME="jenkins" 
CHART_PATH="." 
NAMESPACE="jenkins" 
REPOSITORY="jenkins/jenkins" 
 
if [[ ${OPTION} == "1" ]]; then
  helm install ${RELEASE_NAME} ${CHART_PATH} --values ${VALUE_PATH} --namespace ${NAMESPACE}
elif [[ ${OPTION} == "2" ]]; then
  helm upgrade ${RELEASE_NAME} ${CHART_PATH} --values ${VALUE_PATH} --namespace ${NAMESPACE}
elif [[ ${OPTION} == "3" ]]; then
  helm uninstall ${RELEASE_NAME} --namespace ${NAMESPACE}
elif [[ ${OPTION} == "4" ]]; then
  helm rollback ${RELEASE_NAME}
elif [[ ${OPTION} == "5" ]]; then
  helm template ${RELEASE_NAME} ${REPOSITORY} -f ${VALUE_PATH} > template.yaml
else
  echo "Please give me correct option"
  echo "[1] install [ install resources with current helm values ]"
  echo "[2] upgrade [ upgrade resources with new helm values"
  echo "[3] uninstall [ uninstall all resources ]"
  echo "[4] rollback [ rollback to previous version ]"
  echo "[5] template [ generate manifest file ]"
fi
endsnippet

snippet ansiblerun "Ansible run playbook" b
#!/bin/bash

INVENTORY_PATH="${1:inventory}"
JOB_PATH="${2:echo.yaml}"

ansible-playbook ${JOB_PATH} -i ${INVENTORY_PATH}
endsnippet

snippet arr "Array with multi lines" b
${1:SERVERS}=$(cat <<-END
${2:35.194.109.115}
END
)
endsnippet

snippet charg "Check arguments" b
# check arguments
if [ $# -ne ${1:2} ]; then
    echo "Usage: $0 <API_KEY> <SCOPE>"
    echo "Eg: $0 fg5zzn9m30v5nlinig08iroi67hjy4te 10000"
    exit 1
fi
endsnippet

snippet milisecond "Milisecond" b
TIMESTAMP_MILISECOND=$(date +%s%3N)
endsnippet

snippet timestamp "Timestamp" b
STAMP=$(date +"%s-%A-%d-%B-%Y-@-%Hh%Mm%Ss")
endsnippet

snippet dockerbuild "Docker build" b
#!/bin/bash

NAME=""
TAG=$(git rev-parse HEAD)
FULLNAME="${NAME}:${TAG}"
USERNAME=""
PASSWORD=""

docker login -u ${USERNAME} -p ${PASSWORD} registry.ghsv.vn
docker build -f Dockerfile . -t ${FULLNAME}
docker push ${FULLNAME}
endsnippet

snippet r "Echo and Read" b
echo "$1"
read $2
$3
endsnippet

snippet rr "Read without default" b
read -p "$1 [$2]: " $3
$4
endsnippet

snippet rd "Read with default" b
read -p "$1 [$2]: " $3
$3=${$3:-$2}
$4
endsnippet

snippet terragrunt "Terrragrunt environment" b
#!/bin/bash

OPTION=\${1}

export AWS_PROFILE=""
export GIT_USERNAME=""
export GIT_ACCESS_TOKEN=""
export AWS_ACCESS_KEY_ID=""
export AWS_SECRET_ACCESS_KEY=""

if [[ ${OPTION} == "1" ]]; then
  terragrunt init
  terragrunt run-all plan --terragrunt-non-interactive
elif [[ ${OPTION} == "2" ]]; then 
  terragrunt init
  terragrunt run-all apply --terragrunt-non-interactive
elif [[ ${OPTION} == "3" ]]; then 
  terragrunt init
  terragrunt run-all destroy --terragrunt-non-interactive
else
  echo "Please give me correct option"
  echo "[1] plan [ Initialize and plan ]"
  echo "[2] apply [ Initialize and apply ]"
  echo "[3] destroy [ Initialize and destroy ]"
fi

endsnippet

snippet rdc "Read with default" b
read -p "$(echo -e "$1 [${${2:green2}}$3${nc}]: ")" $4
$4=${$4:-$3}
$5
endsnippet

snippet dn ">/dev/null 2>&1" b
>/dev/null 2>&1
endsnippet

snippet tt "Title" b
####################################################################################################
# $1
####################################################################################################

endsnippet

snippet s "Test" b
#!/bin/bash

$1
endsnippet

snippet ec "Echo" b
echo "${1:Content}"
$2
endsnippet

snippet ece "Echo" i
echo -e "${1:Content}$2"
$2
endsnippet

snippet arg "Argument" b
${1:arg1}=$${2:1}
endsnippet

snippet fn "Function" b
${1:func_name} () {

$2

}
endsnippet

snippet fn2 "Function 2" b
${1:func_name} () {

# get parameters
$2

# logic
$3

}
endsnippet

snippet swc "Switch case" b
case $${1:dayOfWeek} in
  ${2:"Monday"})
    ${3:echo "It's the beginning of the work week!"}
    ;;
  "Tuesday" | "Wednesday" | "Thursday")
    echo "It's the middle of the work week. Keep going!"
    ;;
  "Friday")
    echo "TGIF! It's the end of the work week."
    ;;
  *)
    echo "It's the weekend! Enjoy your time off."
    ;;
esac
endsnippet

snippet nd "Test" b
if [ ! -d ${1:folderPath} ]
then
  ${2:mkdir}	
fi

$3
endsnippet

snippet d "Test" b
if [ -d ${1:folderPath} ]
then
  ${2:mkdir}	
fi

$3
endsnippet

snippet nf "Test" b
if [ ! -f ${1:filePath} ]
then
  ${2:mkdir}	
fi

$3
endsnippet

snippet f "Test" b
if [ -f ${1:filePath} ]
then
  ${2:mkdir}	
fi

$3
endsnippet

snippet cdt "Condition" b
if [[ ${1:true} ]]; then
  ${2:ls -la}	
fi

$3
endsnippet

snippet color "Color" b
black='\033[0;30m'
red='\033[0;31m'
green='\033[0;32m'
orange='\033[0;33m'
blue='\033[0;34m'
purple='\033[0;35m'
cyan='\033[0;36m'
gray='\033[0;37m'
gray2='\033[1;30m'
red2='\033[1;31m'
green2='\033[1;32m'
yellow='\033[1;33m'
blue2='\033[1;34m'
purple2='\033[1;35m'
cyan2='\033[1;36m'
white='\033[1;37m'
nc='\033[0m' # No Color
endsnippet

snippet v2 "Variable" i
${${1:varName}}$2
endsnippet

snippet v3 "Variable" i
$(${1:varName})$2
endsnippet

snippet v4 "Variable" i
$(echo -e "${1:varName}"$2)$3
endsnippet

snippet mysqlbk "mysqlbk" b
#!/bin/bash

# Based on https://gist.github.com/2206527

# Basic variables
mysqlpass="ROOTPASSWORD"
bucket="s3://bucketname"

# Timestamp (sortable AND readable)
stamp=`date +"%s - %A %d %B %Y @ %H%M"`

# List all the databases
databases=`mysql -u root -p$mysqlpass -e "SHOW DATABASES;" | tr -d "| " | grep -v "\(Database\|information_schema\|performance_schema\|mysql\|test\)"`

# Feedback
echo -e "Dumping to \e[1;32m$bucket/$stamp/\e[00m"

# Loop the databases
for db in $databases; do

  # Define our filenames
  filename="$stamp - $db.sql.gz"
  tmpfile="/tmp/$filename"
  object="$bucket/$stamp/$filename"

  # Feedback
  echo -e "\e[1;34m$db\e[00m"

  # Dump and zip
  echo -e "  creating \e[0;35m$tmpfile\e[00m"
  mysqldump -u root -p$mysqlpass --force --opt --databases "$db" | gzip -c > "$tmpfile"

  # Upload
  echo -e "  uploading..."
  s3cmd put "$tmpfile" "$object"

  # Delete
  rm -f "$tmpfile"

done;

# Jobs a goodun
echo -e "\e[1;32mJobs a goodun\e[00m"



### RESTORE

# # Set our variables
# export mysqlpass="ROOTPASSWORD"
# export bucket="s3://bucketname"
# # Get a list of the snapshot dates, newest at the bottom
# s3cmd ls $bucket | sort

# # Set the name of the directory you want to use (ie "1332796733 - Monday 26 March 2012 @ 2218")
# export s3folder="1234567890 - DAY DD MONTH YYYY @ HHMM"
# # Create a temporary directory and change to it
# cd $(mktemp -d)
# # Download all the snapshots
# s3cmd ls "$bucket"/"$s3folder"/ | grep -o "s3://.*\.sql\.gz" | xargs -n 1 -P 10 -I {} s3cmd get {} .
# # Unzip all the files
#  ls | grep "sql.gz" | xargs -n 1 -P 10 -I {} gunzip {} .
#  # Run each file through mysql
 find . -name '*.sql' | awk '{ print "source",$0 }' | mysql -u root -p$mysqlpass --batch

# # Login to MySQL and have a poke
# mysql -u root -p$mysqlpass
endsnippet

snippet k8sbk "Kubernetes backup script" b
#!/bin/bash

export BINARY_PIP_NAME=s3cmd
export BINARY_S3CMD_NAME=s3cmd
export BINARY_ETCD_NAME=etcdctl

# Install s3cmd binary function
install_pip_binary () {
  wget https://bootstrap.pypa.io/get-pip.py 
  python3 get-pip.py
}

# Install s3cmd binary function
install_s3cmd_binary () {
  pip install s3cmd
}

# Install etcd binary function
install_etcd_binary () {
  mkdir /tmp/etcd && cd /tmp/etcd
  rm -rf etcd*
  curl -s https://api.github.com/repos/etcd-io/etcd/releases/latest \
    | grep browser_download_url \
    | grep linux-amd64 \
    | cut -d '"' -f 4 \
    | wget -i -
  tar xvf etcd-v*.tar.gz
  cd etcd-*/
  sudo mv etcd* /usr/local/bin/
  cd ..
  rm -rf etcd*
}

install_if_not_exist () {
  local BINARY=$1
  local FUNCTION=$2
  
  if command -v ${BINARY} &> /dev/null; then
    continue
  else
    $FUNCTION
  fi
}

# Check if binary command exists
install_if_not_exist pip install_pip_binary
install_if_not_exist s3cmd install_s3cmd_binary
install_if_not_exist etcdctl install_etcd_binary

# Chech if s3cmd configured
if [ ! -f $HOME/.s3cfg ]
then
  s3cmd --configure
fi

## BACKUP
# Create backup folder
mkdir -p $HOME/.kubernetes/backup
backupfolder="$HOME/.kubernetes/backup"

# Basic variables
mysqlpass="ROOTPASSWORD"
bucket="s3://bucketname"

# Timestamp (sortable AND readable)
stamp=`date +"%s-%A-%d-%B-%Y-@-%Hh%Mm%Ss"`

# Feedback
echo -e "Dumping to \e[1;32m$bucket/$stamp/\e[00m"

# Define our filenames
filename="$stamp"
backupfile="$backupfolder/$filename.db"
backupzipfile="$backupfolder/$filename.gz"
object="$bucket/$stamp/$filename.gz"

# Feedback
echo -e "\e[1;34m$stamp\e[00m"

# Save snapshot
echo -e "  creating \e[0;35m$backupfile\e[00m"
ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key snapshot save $backupfile
# Create compressed snapshot
gzip -c $backupfile > "$backupzipfile"

# Upload files to s3
echo -e "  uploading..."
s3cmd put "$backupzipfile" "$object"

# Delete local files
rm -f "$backupfile"
rm -f "$backupzipfile"

# Jobs a goodun
echo -e "\e[1;32mJobs a goodun\e[00m"
endsnippet

snippet k8srs "Kubernetes restore script" b
### RESTORE
# Create restore folder
mkdir -p $HOME/.kubernetes/restore
mkdir -p $HOME/.kubernetes/recover
restorefolder="$HOME/.kubernetes/restore"
recoverfolder="$HOME/.kubernetes/recover"

Set our variables
export mysqlpass="PASSWORD"
export bucket="s3://BUCKET_NAME"

# Get a list of the snapshot dates, newest at the bottom
s3cmd ls $bucket | sort

# Set the name of the directory you want to use (ie "1332796733-Monday-26-March-2012-@-22h18m20s")
echo "ie: 1332796733-Monday-26-March-2012-@-22h18m20s"
read -p "$(echo -e "Enter backup folder name: [${green2}1234567890-DAY-DD-MONTH-YYYY-@-HHhMMmSSs${nc}]: ")" sssfolder
#
# Create a temporary directory and change to it
cd $restorefolder

# Download all the snapshots
backupzipfile=$(s3cmd ls "$bucket"/"$sssfolder"/ | awk '{print $4}')
s3cmd get $backupzipfile

# Unzip all the files
gunzip "./$sssfolder"

# Restore it to cluster
etcdutl snapshot restore --data-dir $recoverfolder/$sssfolder $restorefolder/$sssfolder 
endsnippet

snippet exist "Check exist of binary" b
#!/bin/bash

export BINARY_NAME=${1:go}

# Check if "${BINARY_NAME}" command exists using "command -v"
if command -v ${BINARY_NAME} &> /dev/null; then
  echo "${BINARY_NAME} command exists."
else
  echo "${BINARY_NAME} command does not exist."
fi
endsnippet

snippet list "List" b
${1:SERVICES}=$(cat <<-END
$2
END
)
endsnippet

snippet fl "For loop" b
for ${1:service_name} in ${2:$SERVICES}; do
  echo "redeploying $$1"
done
endsnippet

snippet sample "Bash sample" b
#!/bin/bash

####################################################################################################
# IMPORT FILES
####################################################################################################
# source ./file.sh

####################################################################################################
# GET VARIABLES
####################################################################################################

# get variables
OP=\$1
NUMBER=\$2

####################################################################################################
# SET FUNCTION
####################################################################################################

# function 1
hour_to_minute () {

# get parameters
HOURS=\$1

# logic
MINUTES=\$[ \$HOURS * 60 ]

# print out 
echo "\$MINUTES minutes"

}


####################################################################################################
# USE FUNCTION
####################################################################################################
case \$OP in
  "1")
    echo "hour to minute"
    hour_to_minute \$NUMBER
    ;;
  *)
    echo "Only support following operations:"
    echo "1: hour to minute [ sh \$0 1 <NUMBER> ]"
    exit
    ;;
esac
endsnippet

snippet gobuild "Golang build" b
go mod init ${1:name}
go mod tidy
go build
endsnippet

