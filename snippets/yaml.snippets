## Ansible

snippet abp "Ansible builtin ping" b
ansible.builtin.ping:
endsnippet

snippet abd "Ansible builtin debug" b
ansible.builtin.debug:
 Msg: ${1:"Hello world"}
endsnippet

snippet abc "Ansible builtin command" b
ansible.builtin.command: ${1:command}
endsnippet

snippet abs "Ansible builtin shell" b
ansible.builtin.shell: ${1:command}
endsnippet

snippet absc "Ansible builtin script" b
script: ${1:/}
endsnippet

snippet abr "Ansible builtin RPM" b
ansible.builtin.rpm: 
  key: ${1:rpm-link}
  state: ${2:present}
endsnippet

snippet wi "with items" b
with_items:
  - ${1:src}: 
    ${2:src}: 
endsnippet

snippet abcm "Ansible builtin command" b
ansible.builtin.command: ${1:command}
endsnippet

snippet abcm2 "Ansible builtin command 2" b
command: >
  $1
endsnippet

snippet abu "Ansible builtin user create" b
ansible.builtin.user: name=${1:foo} password=${2:password}
endsnippet

snippet abu2 "Ansible builtin user delete" b
ansible.builtin.user: name=${1:foo} state=${2:absent}
endsnippet

snippet abg "Ansible builtin group" b
ansible.builtin.group: name=${1:admin} state=${2:present}
endsnippet

snippet abgu "Ansible builtin get url" b
get_url: 
  url: ${1:link}
  dest: ${1:/}
  checksum: ${1:/}
endsnippet

snippet abgi "Ansible builtin git" b
git: 
  repo: ${1:link}
  version: ${1:8.x}
  dest: ${1:/}
endsnippet

snippet abl "Ansible builtin lineinfile" b
lineinfile: 
  dest: ${1:/}
  regexp: '${1:ENV_VAR=}'
  line: "${1:ENV_VAR=value}"
endsnippet

snippet abst "Ansible builtin stat" b
ansible.builtin.stat: path=${1:/etc/environment} 
endsnippet

snippet abf "Ansible builtin file" b
ansible.builtin.file: src=${1:./} dest=${2:./}
endsnippet

snippet abf2 "Ansible builtin file remove" b
ansible.builtin.file: dest=${1:./} state=${2:absent}
endsnippet

snippet abfd "Ansible builtin file find" b
ansible.builtin.find:
  paths: ${1:/}
  patterns: ${1:*.log}
endsnippet

snippet abn "Ansible builtin npm" b
npm:
  name: ${1:forever}
  state: ${1:state}
  global: ${1:yes}
endsnippet

snippet abfe "Ansible builtin fetch file" b
ansible.builtin.fetch: src=${1:./} dest=${2:./}
endsnippet

snippet abt "Ansible builtin template" b
ansible.builtin.template:
  src: ${1:/}
  dest: ${2:/}
  owner: ${3:root}
  group: ${4:root}
  mode: ${5:0644}
endsnippet

snippet abc "Ansible builtin template" b
ansible.builtin.cron: name=${1:jobname} hour=${2:4} job=${3:/}
endsnippet

snippet abur "Ansible builtin uri" b
ansible.builtin.uri:
  url: ${1:link}
  method: ${2:GET}
  status_code: ${3:200}
endsnippet

snippet abun "Ansible builtin unarchive" b
ansible.builtin.archive:
  src: ${1:src-link}
  dest: ${2:dest}
  remote_src: ${3:yes}
endsnippet

snippet loop "Ansible loop" b
loop:
  - ${1:docker}
endsnippet

snippet anv "Ansible vars" b
vars:
  - ${1:index_file}: ${2:"index.html"}
endsnippet

snippet anvv "Ansible vars only" b
- ${1:index_file}: ${2:"index.html"}
endsnippet

snippet ansvc "Ansible service" b
service: name=${1:httpd} state=${2:started}
endsnippet

snippet any "Ansible yum" b
${1:yum}: name=${2:docker} state=${3:latest}
endsnippet

snippet hv "Ansible host variables" b
$1=$2 
endsnippet

snippet an "Ansible task name" b
- name: ${1:Name}
  ${2:ansvc}
endsnippet

snippet av "Ansible variables" b
{{ ${1:item} }}
endsnippet

snippet ait "Ansible item" i
"{{ ${1:item} }}"
endsnippet

snippet l1 "Line in file" b
lineinfile:
  path: $1
  regexp: $2
  line: $3
endsnippet

snippet r1 "Ansible register" b
register: $1
endsnippet
	
snippet r2 "Ansible roles" b
roles:
  - $1
endsnippet

snippet n1 "Ansible notify" b
notify: ${1:restart_apache}
endsnippet

snippet s1 "Ansible service" b
service:
  name: ${1:docker}
  state: ${2:started}
$3
endsnippet

snippet s2 "Ansible service with enable" b
service:
  name: ${1:docker}
  state: ${2:started}
  enabled: ${3:true}
$4
endsnippet

snippet c1 "Ansible copy" b
copy:
  src: $1
  dest: $2
  owner: $3
  group: $4
  mode: $5
endsnippet
snippet c2 "Ansible change when" b
chnaged_when: ${1:false}
endsnippet

snippet u1 "Ansible unarchive" b
unarchive:
  src: $1
  dest: $2
  remote_src: $3
  owner: $4
  group: $5
  mode: $6
endsnippet

snippet u2 "Ansible user" b
user:
  name: $1
  group: $2
endsnippet

snippet k1 "Ansible authorized_key" b
authorized_key:
  user: $1
  key: "$2"
endsnippet

snippet t1 "Ansible tags" b
tags: ${1:ubuntu,centos}
endsnippet

snippet fpl "First playbook" b
---

- hosts: ${1:all}
  become: ${2:true}
  ${3:tasks}:
  - name: ${4:Name}
    ${5:yum}: name=${6:tmux} state=${7:latest}
$8
endsnippet

snippet pl "Playbook" b
- hosts: ${1:all}
  become: ${2:true}
  ${3:tasks}:
  - name: ${4:Name}
    ${5:yum}: name=${6:tmux} state=${7:latest}
$8
endsnippet

snippet ts "Ansible task" b
- name: ${1:Name}
  ${2:yum}: name=${3:tmux} state=${4:latest}
$5
endsnippet

snippet w1 "Ansible when condition" b
when: ${1:ansible_distribution} ${2:==} ${3:"Ubuntu"}
$4
endsnippet

snippet hdl "Ansible handlers" b
handlers:
  - name: ${1:restart}
endsnippet

## K8S

## POD
snippet pod "K8s normal pod" b
apiVersion: v1
kind: Pod
metadata:
  name: ${1:podName}
spec:
  containers:
  - name: ${2:containerName}
    image: ${3:image}
    ports:
    - containerPort: ${4:Port}
endsnippet

snippet pod2 "Test" b
apiVersion: v1
kind: Pod
metadata:
  name: ${1:podName}
spec:
  containers:
  - name: ${2:containerName}
    image: ${3:image}
    ports:
    - containerPort: ${4:Port}
    volumeMounts:
    - name: ${5:volumeName} # The volume called html is mounted at /usr/share/nginx/html in the container
      mountPath: ${6:mountPath(container)}
      ${7:ReadOnly}: ${8:true}
volumes: # define volumes
  - name: $5 # name of the volumes
    ${9:emptyDir}: ${10:{}} # define type is emptyDir
endsnippet

snippet pod3 "K8s pod with env and mount" b
apiVersion: v1
kind: Pod
metadata:
  name: ${1:podName}
spec:
  containers:
  - name: ${2:containerName}
    image: ${3:image}
    ports:
    - containerPort: ${4:Port}
    volumeMounts:
    - name: ${5:volumeName} # The volume called html is mounted at /usr/share/nginx/html in the container
      mountPath: ${6:mountPath(container)}
      ${7:ReadOnly}: ${8:true}
      env: # pass env to container
        - name: ${9:PORT} # env name
          value: ${10:"5000"} # env value
volumes: # define volumes
  - name: $5 # name of the volumes
    ${11:emptyDir}: ${12:{}} # define type is emptyDir
endsnippet
## SET
snippet rc "K8s normal replication" b
apiVersion: v1
kind: ReplicationController
metadata:
  name: ${1:my-rc}
spec:
  replicas:  ${2:3} # number of the pod
  selector: # The pod selector determining what pods the RC is operating on
    ${3:app}: ${4:appName} #label value
  template: # pod template
    metadata:
      labels:
        ${5:podLabel}: ${6:podLabelValue} # label value
    spec:
      containers:
      - image: ${7:image} # image used to run container
        name: ${8:containerName} # name of the container
        ports:
          - containerPort: ${9:8080} # pod of the container
endsnippet

snippet rc2 "k8s replication with mount" b
apiVersion: v1
kind: ReplicationController
metadata:
  name: ${1:my-rc}
spec:
  replicas:  ${2:3} # number of the pod
  selector: # The pod selector determining what pods the RC is operating on
    ${3:app}: ${4:appName} #label value
  template: # pod template
    metadata:
      labels:
        ${5:podLabel}: ${6:podLabelValue} # label value
    spec:
      containers:
      - image: ${7:image} # image used to run container
        name: ${8:containerName} # name of the container
        ports:
          - containerPort: ${9:8080} # pod of the container
    	volumeMounts:
    	- name: ${10:volumeName} # The volume called html is mounted at /usr/share/nginx/html in the container
      	mountPath: ${11:mountPath(container)}
      	${12:ReadOnly}: ${13:true}
    volumes: # define volumes
  	- name: $10 # name of the volumes
    	${16:emptyDir}: ${17:{}} # define type is emptyDir
endsnippet

snippet rc3 "k8s replication with env and mount" b
apiVersion: v1
kind: ReplicationController
metadata:
  name: ${1:my-rc}
spec:
  replicas:  ${2:3} # number of the pod
  selector: # The pod selector determining what pods the RC is operating on
    ${3:app}: ${4:appName} #label value
  template: # pod template
    metadata:
      labels:
        ${5:podLabel}: ${6:podLabelValue} # label value
    spec:
      containers:
      - image: ${7:image} # image used to run container
        name: ${8:containerName} # name of the container
        ports:
          - containerPort: ${9:8080} # pod of the container
    	volumeMounts:
    	- name: ${10:volumeName} # The volume called html is mounted at /usr/share/nginx/html in the container
      	mountPath: ${11:mountPath(container)}
      	${12:ReadOnly}: ${13:true}
      	env: # pass env to container
        - name: ${14:PORT} # env name
          value: ${15:"5000"} # env value
    volumes: # define volumes
  	- name: $10 # name of the volumes
    	${16:emptyDir}: ${17:{}} # define type is emptyDir
endsnippet

snippet rs "k8s normal replicaSet" b
apiVersion: apps/v1 # change version API
kind: ReplicaSet # change resource name
metadata:
  name: ${1:myReplicaSet}
spec:
  replicas: ${2:amount}
  selector:
    matchLabels: # change here 
      ${3:app}: ${4:appName}
  template:
    metadata:
      labels:
        ${5:podLabel}: ${6:podLabelValue}
    spec:
      containers:
      - image: ${7:imageName}
        name:${8:containerName} 
        ports:
          - containerPort: ${9:8080}
endsnippet

snippet rs2 "k8s replicaSet with mount" b
apiVersion: apps/v1 # change version API
kind: ReplicaSet # change resource name
metadata:
  name: ${1:myReplicaSet}
spec:
  replicas: ${2:amount}
  selector:
    matchLabels: # change here 
      ${3:app}: ${4:appName}
  template:
    metadata:
      labels:
        ${5:podLabel}: ${6:podLabelValue}
    spec:
      containers:
      - image: ${7:imageName}
        name:${8:containerName} 
        ports:
          - containerPort: ${9:8080}
    	volumeMounts:
    	- name: ${10:volumeName} # The volume called html is mounted at /usr/share/nginx/html in the container
      	mountPath: ${11:mountPath(container)}
      	${12:ReadOnly}: ${13:true}
    volumes: # define volumes
  	- name: $10 # name of the volumes
    	${14:emptyDir}: ${15:{}} # define type is emptyDir
endsnippet

snippet rs3 "k8s replicaSet with env and mount" b
apiVersion: apps/v1 # change version API
kind: ReplicaSet # change resource name
metadata:
  name: ${1:myReplicaSet}
spec:
  replicas: ${2:amount}
  selector:
    matchLabels: # change here 
      ${3:app}: ${4:appName}
  template:
    metadata:
      labels:
        ${5:podLabel}: ${6:podLabelValue}
    spec:
      containers:
      - image: ${7:imageName}
        name:${8:containerName} 
        ports:
          - containerPort: ${9:8080}
    	volumeMounts:
    	- name: ${12:volumeName} # The volume called html is mounted at /usr/share/nginx/html in the container
      	mountPath: ${13:mountPath(container)}
      	${14:ReadOnly}: ${15:true}
      	env: # pass env to container
        - name: ${16:PORT} # env name
          value: ${17:"5000"} # env value
    volumes: # define volumes
  	- name: $12 # name of the volumes
    	${18:emptyDir}: ${19:{}} # define type is emptyDir
endsnippet

snippet dms "k8s normal daemonSet" b
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ${1:myDaemonSet}
spec:
  selector:
    matchLabels:
      ${2:daemonSetLabel}: ${3:daemonSetLabelValue}
  template:
    metadata:
      labels:
        ${4:podLabel}: ${5:podLabelValue}
    spec:
      nodeSelector:
        ${6:nodeLabelName}: ${7:nodeLabelNameValue} 
      containers:
        - name: ${8:containerName}
          image: ${9:containerImage}
      	env: # pass env to container
        - name: ${10:PORT} # env name
          value: ${11:"5000"} # env value
endsnippet

snippet dms2 "k8s daemonSet with mount" b
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ${1:myDaemonSet}
spec:
  selector:
    matchLabels:
      ${2:daemonSetLabel}: ${3:daemonSetLabelValue}
  template:
    metadata:
      labels:
        ${4:podLabel}: ${5:podLabelValue}
    spec:
      nodeSelector:
        ${6:nodeLabelName}: ${7:nodeLabelNameValue} 
      containers:
        - name: ${8:containerName}
          image: ${9:containerImage}
      volumeMounts:
      - name: ${10:volumeName} # The volume called html is mounted at /usr/share/nginx/html in the container
        mountPath: ${11:mountPath(container)}
        ${12:ReadOnly}: ${13:true}
     volumes: # define volumes
    - name: $10 # name of the volumes
      ${14:emptyDir}: ${15:{}} # define type is emptyDir
endsnippet
	
snippet dms3 "k8s daemonSet with env and mount" b
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ${1:myDaemonSet}
spec:
  selector:
    matchLabels:
      ${2:daemonSetLabel}: ${3:daemonSetLabelValue}
  template:
    metadata:
      labels:
        ${4:podLabel}: ${5:podLabelValue}
    spec:
      nodeSelector:
        ${6:nodeLabelName}: ${7:nodeLabelNameValue} 
      containers:
        - name: ${8:containerName}
          image: ${9:containerImage}
      volumeMounts:
      - name: ${10:volumeName} # The volume called html is mounted at /usr/share/nginx/html in the container
        mountPath: ${11:mountPath(container)}
        ${12:ReadOnly}: ${13:true}
        env: # pass env to container
         - name: ${14:PORT} # env name
           value: ${15:"5000"} # env value
     volumes: # define volumes
    - name: $10 # name of the volumes
      ${16:emptyDir}: ${17:{}} # define type is emptyDir
endsnippet

snippet dpl "k8s normal deployment" b
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${1:deployName}
  labels:
    app: ${2:deployAppName}
spec:
  revisionHistoryLimit: ${3:1}
  strategy: # change here
    type: ${4:RollingUpdate} # you can choose Recreate instead of RollingUpdate
  replicas: ${5:amountOfReplica}
  selector:
    matchLabels:
      app: ${6:matchePodLabels}
  template:
    metadata:
      labels:
        app: ${7:podLabels}
    spec:
      containers:
      - name: ${8:containerName}
        image: ${9:image}
        ports:
        - containerPort: ${10:containerPort}
endsnippet

snippet dpl2 "k8s normal deployment with mount" b
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${1:deployName}
  labels:
    app: ${2:deployAppName}
spec:
  revisionHistoryLimit: ${3:1}
  strategy: # change here
    type: ${4:RollingUpdate} # you can choose Recreate instead of RollingUpdate
  replicas: ${5:amountOfReplica}
  selector:
    matchLabels:
      app: ${6:matchePodLabels}
  template:
    metadata:
      labels:
        app: ${7:podLabels}
    spec:
      containers:
      - name: ${8:containerName}
        image: ${9:image}
        ports:
        - containerPort: ${10:containerPort}
    	volumeMounts:
    	- name: ${11:volumeName} # The volume called html is mounted at /usr/share/nginx/html in the container
      	mountPath: ${12:mountPath(container)}
      	${13:ReadOnly}: ${14:true}
    volumes: # define volumes
  	- name: $11 # name of the volumes
    	${15:emptyDir}: ${16:{}} # define type is emptyDir
endsnippet

snippet dpl3 "k8s normal deployment with env and mount" b
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${1:deployName}
  labels:
    app: ${2:deployAppName}
spec:
  revisionHistoryLimit: ${3:1}
  strategy: # change here
    type: ${4:RollingUpdate} # you can choose Recreate instead of RollingUpdate
  replicas: ${5:amountOfReplica}
  selector:
    matchLabels:
      app: ${6:matchePodLabels}
  template:
    metadata:
      labels:
        app: ${7:podLabels}
    spec:
      containers:
      - name: ${8:containerName}
        image: ${9:image}
        ports:
        - containerPort: ${10:containerPort}
    	volumeMounts:
    	- name: ${11:volumeName} # The volume called html is mounted at /usr/share/nginx/html in the container
      	mountPath: ${12:mountPath(container)}
      	${13:ReadOnly}: ${14:true}
      	env: # pass env to container
        - name: ${15:PORT} # env name
          value: ${16:"5000"} # env value
    volumes: # define volumes
  	- name: $11 # name of the volumes
    	${17:emptyDir}: ${18:{}} # define type is emptyDir
endsnippet

snippet dplnginx "Nginx deployment sample" b
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
endsnippet

snippet sts "k8s normal statefulSet" b
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ${1:statefulSetName}
spec:
  serviceName: ${2:serverName}# the name of service
  replicas: ${3:amount}
  template: # pod template
    metadata:
      labels:
        ${4:podLabelName}: ${5:podLabelValue}
    spec:
      containers:
        - name: ${6:containerName}
          image: ${7:containerImage}
          ports:
            - name: ${8:http}
              containerPort: ${9:8080}
endsnippet

snippet sts2 "k8s normal statefulSet with mount" b
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ${1:statefulSetName}
spec:
  serviceName: ${2:serverName}# the name of service
  replicas: ${3:amount}
  template: # pod template
    metadata:
      labels:
        ${4:podLabelName}: ${5:podLabelValue}
    spec:
      containers:
        - name: ${6:containerName}
          image: ${7:containerImage}
          ports:
            - name: ${8:http}
              containerPort: ${9:8080}
    	  volumeMounts:
    	  - name: ${10:volumeName} # The volume called html is mounted at /usr/share/nginx/html in the container
      	  mountPath: ${11:mountPath(container)}
      	  ${12:ReadOnly}: ${13:true}
      volumes: # define volumes
  	  - name: $10 # name of the volumes
    	  ${14:emptyDir}: ${15:{}} # define type is emptyDir
endsnippet

snippet sts3 "k8s normal statefulSet with env and mount" b
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ${1:statefulSetName}
spec:
  serviceName: ${2:serverName}# the name of service
  replicas: ${3:amount}
  template: # pod template
    metadata:
      labels:
        ${4:podLabelName}: ${5:podLabelValue}
    spec:
      containers:
        - name: ${6:containerName}
          image: ${7:containerImage}
          ports:
            - name: ${8:http}
              containerPort: ${9:8080}
    	  volumeMounts:
    	  - name: ${10:volumeName} # The volume called html is mounted at /usr/share/nginx/html in the container
      	  mountPath: ${11:mountPath(container)}
      	  ${12:ReadOnly}: ${13:true}
      	  env: # pass env to container
          - name: ${14:PORT} # env name
            value: ${15:"5000"} # env value
      volumes: # define volumes
  	  - name: $10 # name of the volumes
    	  ${16:emptyDir}: ${17:{}} # define type is emptyDir
endsnippet

## SERVICE
snippet svc "Test" b
apiVersion: v1
kind: Service
metadata:
  name: ${1:Name}
spec:
  selector:
      ${2:app} : ${3:myAppName}
  ports:
    - protocol: ${4:protocol}
      port: ${5:Port}
      targetPort: ${6:targetPort}
endsnippet

snippet svc2 "k8s svc nodeport" b
apiVersion: v1
kind: Service
metadata:
  name: ${1:Name}
spec:
  type: NodePort
  selector:
      ${2:app} : ${3:myAppName}
  ports:
    - protocol: ${4:TCP}
      port: ${5:80}
      targetPort: ${6:8080}
      nodePort: ${7:31000}
endsnippet

snippet svc3 "k8s svc loadbalancer" b
apiVersion: v1
kind: Service
metadata:
  name: ${1:serverName}
spec:
  selector:
    ${2:podLabelName}: ${3:podLabelNameValue}
  type: LoadBalancer
  ports:
    - protocol: ${4:TCP}
      port: ${5:80}
      targetPort: ${6:8080}
endsnippet

snippet ing "k8s ingress" b
piVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: ${1:myIngressName}
spec:
  rules:
    - host: ${2:replicaSet.example.com} # domain name
  http:
    paths:
      - path: ${3:/}
        backend:
          serviceName: ${4:serviceName} # name of the service inside cluster
          servicePort: ${5:serverPort}
endsnippet

snippet rrtg "Nginx rewrite target annotation" b
    nginx.ingress.kubernetes.io/rewrite-target: /
endsnippet

snippet ingnginx "Nginx Ingress" b
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ${1:service-2048}
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: ${2:/}
spec:
  ingressClassName: nginx
  rules:
  - http:
      paths:
      - path: ${3:/path-2048}
        pathType: Prefix
        backend:
          service:
            name: ${4:service-2048}
            port:
              number: ${5:80}
endsnippet

snippet ingalb "ALB Ingress" b
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ${1:ingress-2048}
  annotations:
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
spec:
  ingressClassName: alb
  rules:
    - http:
        paths:
        - path: ${2:/}
          pathType: Prefix
          backend:
            service:
              name: ${3:service-2048}
              port:
                number: ${4:80}
endsnippet

snippet gce "Test" b
- name: ${1:htlm}
  gcePersistentDisk: # google cloud disk volume
    pdName: ${2:persistentVolumeName} # name of the persistent disk on google cloud
    fsType: ext4
endsnippet

snippet aws "k8s aws volume inside resources" b
- name: ${1:html}
  awsElasticBlockStore: # amazon web service volume
    volumeID: ${2:volumeID} # volume of the aws ebs
    fsType: ext4
endsnippet

snippet mapu "EKS Map users" b
  mapUsers: |
    - userarn: arn:aws:iam::${1:424432388155}:user/${2:developer}
      username: $2
      groups: 
      - ${3:reader}
endsnippet

snippet mapr "EKS Map roles" b
  mapRoles: |
    - rolearn: arn:aws:iam::${1:424432388155}:role/${2:eks-admin}
      username: $2
      groups:
      - system:masters
endsnippet

snippet map "Test" b
apiVersion: v1
kind: ConfigMap
metadata:
  name: ${1:configMapName}
data:
  ${2:DB}: ${3:postgre}
endsnippet

snippet nw "k8s network policy" b
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ${1:networkPolicyName}
spec:
  podSelector:
    matchLabels:
      ${2:podLabelName}: ${3:podLabelValue} # Adjust the label to match the pods you want to allow
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
      - ipBlock:
          cidr: ${4:10.0.0.0/16}
      - podSelector:
          matchLabels:
            ${5:role}: ${6:database} # Adjust the label to match the allowed pods
  egress:
    - to:
      - ipBlock:
          cidr: ${7:10.0.0.0/16}
      - podSelector:
          matchLabels:
            ${8:role}: ${9:database} # Adjust the label to match the allowed pods
endsnippet

snippet sc "k8s secret" b
apiVersion: v1
kind: Secret
metadata:
  name: ${1:my-secret}
type: Opaque
data:
  ${2:username}: ${3:<base64-encoded-username>}
endsnippet

snippet sc2 "k8s secret basic auth" b
apiVersion: v1
kind: Secret
metadata:
  name: ${1:my-basic-auth-secret}
type: kubernetes.io/basic-auth
data:
  ${2:username}: ${3:<base64-encoded-username>}
endsnippet

snippet sc3 "k8s secret docker registry" b
apiVersion: v1
kind: Secret
metadata:
  name: ${1:my-docker-secret}
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: ${2:<base64-encoded-docker-config>}
endsnippet

snippet sc4 "k8s secret tls cert" b
apiVersion: v1
kind: Secret
metadata:
  name: ${1:my-tls-secret}
type: kubernetes.io/tls
data:
  tls.crt: ${2:<base64-encoded-certificate>}
  tls.key: ${3:<base64-encoded-private-key>}
endsnippet

snippet stc "k8s storage class" b
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ${1:my-storage-class}
provisioner: kubernetes.io/${2:aws-ebs} # aws-ebs | gcp-pd | rbd | azure-disk | azure-file | portworx-volume | vsphere-volume | no-provisioner
parameters: # type | fsType | encrypted | iopsPerGB | zones | replication-tye 
  type: ${3:gp2} # io1 | io2 | gp2 | gp3
  fsType: ${4:ext4}
  encrypted: "${5:true}"  
  iopsPerGB: "${6:10}"   
  zones: ${7:ap-northeast-1a} # Can use multi zone seperate by comma
  replication-type: none 
reclaimPolicy: ${8:Delete} # Delete | Retain | Snapshot
allowVolumeExpansion: ${9:false} # true or false
mountOption:
  - debug
volumeBindingMode: ${10:WaitForFirstConsumer} # WaitForFirstConsumer | Immediate
endsnippet

snippet cfg "k8s configmap" b
apiVersion: v1
kind: ConfigMap
metadata:
  name: ${1:my-configmap}
data:
  ${2:key1}: ${3:value1}
endsnippet

snippet cfg2 "k8s configmap 3" b
apiVersion: v1
kind: ConfigMap
metadata:
  name: ${1:my-configmap-files}
data:
  ${2:special-key}: |-
    ${3:key1}=${4:value1}
endsnippet

snippet cfg3 "k8s configmap 3" b
piVersion: v1
kind: ConfigMap
metadata:
  name: ${1:my-configmap-binary}
data:
  binary-data: ${2:<base64-encoded-binary-content>}
endsnippet

snippet cfg4 "k8s configmap 4" b
apiVersion: v1
kind: ConfigMap
metadata:
  name: ${1:my-configmap-yaml}
data:
  ${2:config.yaml}: |
    ${3:key1}: ${4:value1}
endsnippet

snippet pv "k8s persistence volume" b
apiVersion: v1
kind: PersistentVolume
metadata:
  name: ${1:my-pv}
spec:
  capacity:
    storage: ${2:1Gi}
  accessModes:
    - ${3:ReadWriteOnce} # ReadWriteOnce | ReadOnlyMany | ReadWriteMany
  persistentVolumeReclaimPolicy: ${4:Retain} # Retain | Delete | Snapshot
  storageClassName: ${5:my-storage-class}
  hostPath:
    path: ${6:/path/on/host}
endsnippet

snippet hpa "k8s HPA" b
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: ${1:my-hpa}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: ${2:Deployment} # Pod | ReplicationSet ,...
    name: ${3:my-deployment}
  minReplicas: ${4:2}
  maxReplicas: ${5:5}
  metrics:
    - type: Resource
      resource:
        name: ${6:cpu}
        targetAverageUtilization: ${7:80}
    - type: Resource
      resource:
        name: ${7:memory}
        targetAverageValue: ${8:200Mi}
endsnippet

snippet ns "K8s namespace" b
apiVersion: v1
kind: Namespace
metadata:
  name: ${1:my-namespace}
endsnippet

snippet jb "k8s job" b
apiVersion: batch/v1
kind: Job
metadata:
  name: ${1:my-job}
spec:
  template:
    metadata:
      name: ${2:my-pod}
    spec:
      containers:
      - name: ${3:my-container}
        image: ${4:my-image:latest}
  backoffLimit: ${5:3}
endsnippet

snippet cjb "k8s cronjob" b
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: ${1:my-cronjob}
spec:
  schedule: "${2:*/5 * * * *}"
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            ${3:app}: ${4:my-cronjob}
        spec:
          containers:
          - name: ${5:my-container}
            image: ${6:my-image:latest}
  successfulJobsHistoryLimit: ${7:3}
  failedJobsHistoryLimit: ${8:1}
endsnippet

snippet sa "Service Account" b
apiVersion: v1
kind: ServiceAccount
metadata:
  # Replace with your desired name
  name: ${1:my-service-account}
  # Optional namespace (defaults to "default")
  # namespace: my-namespace
endsnippet

snippet gr "K8s group" b
apiVersion: v1
kind: Group
metadata:
  name: ${1:editors}
endsnippet

snippet usb "User subject bind" b
apiVersion: rbac.authorization.k8s.io/v1
kind: UserSubjectBind
metadata:
  name: ${1:<username>-editors-bind}
subjects:
- kind: User
  name: ${2:<username>}
objectRef:
  kind: Group
  name: ${3:editors}
endsnippet

snippet rl "Role" b
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ${1:my-role}
  namespace: ${2:my-namespace}
rules:
- apiGroups: ["${3:my-group}"]
  resources: ["${4:pods}"]
  verbs: [${5:"get"}] # get | list | watch | create | update | patch | delete
endsnippet

snippet rlb "RoleBinding" b
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: ${1:my-role-binding}
  namespace: ${2:my-namespace}
subjects:
- kind: ${3:ServiceAccount}
  name: ${4:default}
  namespace: ${5:my-namespace}
roleRef:
  kind: ${6:Role}
  name: ${7:my-role}
  apiGroup: rbac.authorization.k8s.io
endsnippet

snippet clr "k8s clusterRole" b
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: ${3:my-cluster-role}
rules:
- apiGroups: ["${2:my-group}"]
  resources: ["${3:pods}"]
  verbs: [${5:"get"}] # get | list | watch | create | update | patch | delete
- apiGroups: ["${6:my-group}"]
  resources: ["${7:deployments}"]
  verbs: [${5:"get"}] # get | list | watch | create | update | patch | delete
endsnippet

snippet clrb "k8s clusterRoleBinding" b
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: ${1:my-cluster-role-binding}
subjects:
- kind: ${2:ServiceAccount}
  name: ${3:default}
  namespace: ${4:default}
roleRef:
  kind: ${5:ClusterRole}
  name: ${6:my-cluster-role}
  apiGroup: rbac.authorization.k8s.io
endsnippet

snippet pv "Test" b
apiVersion: v1
kind: PersistentVolume
metadata:
  name: ${1:my-pvc}
spec:
  capacity:
    storage: ${2:5Gi}
  volumeMode: ${3:Filesystem}
  accessModes:
    - ${4:ReadWriteOnce} # ReadWriteOnce | ReadOnlyMany | ReadWriteMany
  persistentVolumeReclaimPolicy: ${5:Recycle}
  storageClassName: ${6:myStorageClass} 
endsnippet

snippet pvc "k8s pvc" b
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ${1:my-pvc}
spec:
  accessModes:
    - ${2:ReadWriteOnce} # ReadWriteOnce | ReadOnlyMany | ReadWriteMany
  storageClassName: ${3:my-storage-class}
  resources:
    requests:
      storage: ${4:5Gi}
endsnippet

snippet argocd "k8s argocd" b
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ${1:argocd-app}
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/${2:haquocdat543}/${3:devops-argocd}.git 
    targetRevision: ${4:HEAD}
    path: ${5:resources}
  destination:
    server: https://kubernetes.default.svc
    namespace: argocd
  syncPolicy:
    syncOptions:
      - CreateNamespace = ${6:true}
    automated:
      selfHeal: ${7:true}
      prune:    ${8:true}
endsnippet

snippet argoro "k8s argo rollout" b
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: ${1:bluegreen-demo}
  labels:
    app: ${2:bluegreen-demo}
spec:
  replicas: ${3:2}
  revisionHistoryLimit: ${4:1}
  selector:
    matchLabels:
      app: ${4:bluegreen-demo}
  template:
    metadata:
      labels:
        app: ${5:bluegreen-demo}
    spec:
      containers:
        - name: ${6:bluegreen-demo}
          image: ${7:argoproj/rollouts-demo:green}
          imagePullPolicy: ${8:Always}
          ports:
            - name: ${9:http}
              protocol: ${10:TCP}
              containerPort: ${11:8080}
  strategy:
    blueGreen:
      autoPromotionEnabled: ${12:false}
      activeService: ${13:bluegreen-demo}
      previewService: ${14:bluegreen-demo-preview}
endsnippet

snippet env "K8s Env" b
env: # pass env to container
  - name: ${1:PORT} # env name
    value: ${2:"5000"} # env value
endsnippet

snippet v2 "Container env variable" b
- name: ${1:PORT} # env name
  value: ${2:"5000"} # env value
endsnippet

snippet v3 "Svc port" b
- protocol: ${1:TCP}
  port: ${2:80}
  targetPort: ${3:8080}
endsnippet

snippet v4 "Nodeport port" b
- protocol: ${1:TCP}
  port: ${2:80}
  targetPort: ${3:8080}
  nodePort: ${4:31000}
endsnippet

snippet v5 "Secret variable" b
${1:password}: ${2:<base64-encoded-password>}
endsnippet

snippet v6 "node Selector" b
nodeSelector:
    ${1:disktype}: ${2:ssd}
endsnippet

snippet tol "k8s toleration" b
tolerations:
  - key: ${1:node-type}
    Operator: ${2:Equal}
    value: ${3:production}
    effect: ${4:NoSchedule} # NoSchedule | PreferNoSchedule | NoExecute
endsnippet

snippet naff "k8s node Affinity" b
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
          - ${1:key}: ${2:disktype}
            operator: ${3:In}
            values:
              - "${4:ssd}"
endsnippet

snippet paff "k8s pod affinity" b
affinity:
  podAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      - topologyKey: kubernetes.io/hostname
        labelSelector:
            matchLabels:
              ${1:app}: ${2:database}
endsnippet

snippet imgsc "ImageSecretPull" b
imagePullSecrets:
- name: ${1:my-registry-key}
endsnippet

snippet vol "k8s volume inside resources" b
volumes:
  - name: ${1:my-persistent-storage}
    persistentVolumeClaim:
      claimName: ${1:my-pvc}
endsnippet

snippet vol2 "k8s volume EmptyDir" b
- name: ${1:html}
  emptyDir: ${2:{}}
endsnippet

snippet vol3 "k8s volume hostPath" b
- name: ${1:log}
  hostPath: 
    path: ${2:/var/log}
endsnippet

snippet vol4 "k8s volume gitRepo" b
- name: ${1:html}
  gitRepo: 
    repository: https://github.com/${2:luksa}/${3:kubia-website-example}.git 
    revision: ${4:master }
    directory: ${5:.}
endsnippet

snippet vol5 "k8s volume ConfigMap" b
- name: ${1:config}
  configMap:
    name: ${2:nginx-config}
endsnippet

snippet vlm "k8s volume mount" b
volumeMounts:
    - name: ${1:mongodb-data}
      mountPath: ${2:/data/db}
endsnippet

snippet vm "k8s volume mount" b
- name: ${1:mongodb-data}
  mountPath: ${2:/data/db}
endsnippet

snippet vm1 "k8s readOnly" b
${1:ReadOnly}: ${2:true}
endsnippet

snippet meshgw "k8s consul mesh gateway" b
piVersion: consul.hashicorp.com/v1alpha1
kind: Mesh
metadata:
  name: ${1:mesh}
spec:
  peering:
    peerThroughMeshGateways: ${2:true}
endsnippet

snippet expsvc "k8s consul exported service" b
apiVersion: consul.hashicorp.com/v1alpha1
kind: ExportedServices
metadata:
  name: ${1:default }
spec:
  services:
    - name: "${2:shippingservice}" 
      consumers:
      - peer: ${3:eks }
endsnippet

snippet svcin "k8s consul service intention" b
apiVersion: consul.hashicorp.com/v1alpha1
kind: ServiceIntentions
metadata:
  name: ${1:shipping-allow-eks}
spec:
  destination:
    name: ${2:shippingservice}
  sources:
   - name: ${3:frontendxx} # name of service within eks sending traffic to frontend
     action: ${4:allow}
     peer: ${5:eks}
endsnippet

snippet svcre "k8s consul service resolver" b
apiVersion: consul.hashicorp.com/v1alpha1
kind: ServiceResolver
metadata:
  name: ${1:shippingservice}
spec:
  connectTimeout: ${2:15s}
  failover:
    '*':
      targets:
        - peer: '${3:lke}'
endsnippet

snippet consul "k8s consul file" b
global:
  image: "hashicorp/consul:1.14.0"
  peering:
    enabled: ${1:true}
  tls:
    enabled: ${2:true}

server:
  replicas: ${3:1}
  bootstrapExpect: ${4:1}
  extraConfig: |
    {
      "log_level": "TRACE"
    }

connectInject:
  enabled: ${5:true}
  default: ${6:true}

meshGateway:
  enabled: ${7:true}
  replicas: ${8:1}

controller:
  enabled: ${9:true}

ui:
  enabled: ${10:true}
  service:
    enabled: ${11:true}
    type: ${12:LoadBalancer}
endsnippet

snippet hredis "k8s redis with helm" b
master:
  password: "${1:integration}"
  resources:
    requests:
      memory: "${2:1Gi}"
      cpu: "${3:500m}"
    limits:
      memory: "${4:1Gi}"
      cpu: "${5:500m}"
persistence:
  enabled: true

pdb:
  create: true
  minAvailable: ${6:1}
  maxUnavailable: "$7"

architecture: ${8:standalone}

metrics:
  enabled: ${9:true}
  service:
    type: ${10:Loadbalancer}
endsnippet

snippet hrln "Helm Release Name" b
.Release.Name
endsnippet

snippet hrlns "Helm Release Namespace" b
.Release.Namespace
endsnippet

snippet hrliu "Helm Release Is Upgrade" b
.Release.IsUpgrade
endsnippet

snippet hrlii "Helm Release Is Install" b
.Release.IsInstall
endsnippet

snippet hrls "Helm Release Service" b
.Release.Service
endsnippet

snippet hrlr "Helm Release Revision" b
.Release.Revision
endsnippet

snippet hfg "Helm Files Get" b
.Files.Get
endsnippet

snippet hfgb "Helm Files Get Bytes" b
.Files.GetBytes
endsnippet

snippet hfgl "Helm Files Glob" b
.Files.Glob
endsnippet

snippet hfl "Helm Files Lines" b
.Files.Lines
endsnippet

snippet hfas "Helm Files As Secret" b
.Files.AsSecret
endsnippet

snippet hfac "Helm Files As Config" b
.Files.AsConfig
endsnippet

snippet hcav "Helm Capabilities API Version" b
.Capabilities.APIVersions
endsnippet

snippet hcavh "Helm Capabilities API Version Has" b
.Capabilities.APIVersions.Has $version
endsnippet

snippet hckv "Helm Capabilities KubeVersion" b
.Capabilities.KubeVersion
endsnippet

snippet hcav "Helm Capabilities API Version" b
.Files.Get
endsnippet

snippet hckvmj "Helm Capabilities KubeVersion Major" b
.Capabilities.KubeVersion.Major
endsnippet

snippet hckvmi "Helm Capabilities KubeVersion Minor" b
.Capabilities.KubeVersion.Minor
endsnippet

snippet htn "Helm Template Name" b
.Template.Name
endsnippet

snippet htb "Helm Template Basepath" b
.Template.Basepath
endsnippet

snippet hch "Helm Chart" b
.Chart.
endsnippet

snippet hvl "Helm Values" b
.Values.
endsnippet

snippet hfq "Helm Quote Function" b
quote
endsnippet

snippet hfr "Helm Repeat Function" b
repeat ${1:5}
endsnippet

snippet hfu "Helm Upper Function" b
upper
endsnippet

snippet hfl "Helm Lower Function" b
lower
endsnippet

snippet hfi "Helm Include Function" b
include "$1"$2
endsnippet

snippet hfrq "Helm Require Function" b
require "$1"$2
endsnippet

snippet hfin "Helm Indent Function" b
indent ${1:5}
endsnippet

snippet hfni "Helm Nindent Function" b
nindent ${1:5}
endsnippet

snippet hft "Helm ToYaml Function" b
toYaml 
endsnippet

snippet hfd "Helm Default Function" b
default "$1"$2
endsnippet

snippet kz "Kustomize" b
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - ${1:api-depl.yaml}
endsnippet

snippet kzfl "Kustomize flux" b
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
metadata:
  name: $1
  namespace: $2

resources:
  - ${3:api-depl.yaml}
endsnippet

snippet kzns "Kustomize namspace" b
namespace: ${1:your-namespace}
endsnippet

snippet kzim "Kustomize images" b
images:
  - name: ${1:httpd}
    newName: ${2:nginx}
    newTag: ${3:1.21.0}
endsnippet

snippet kznpf "Kustomize Name Prefix" b
namePrefix: ${1:LAB-}
endsnippet

snippet kznsf "Kustomize Name Suffix" b
nameSuffix: ${1:-dev}
endsnippet

snippet kzpf "Kustomize Prefix" b
Prefix: ${1:LAB-}
endsnippet

snippet kzsf "Kustomize Suffix" b
Suffix: ${1:-dev}
endsnippet

snippet kzca "Kustomize Annotation" b
commonAnnotations:
  ${1:branch}: ${2:master}
endsnippet

snippet kzcl "Kustomize Labels" b
commonLabels:
  ${1:name}: ${2:value}
endsnippet

snippet kzb "Kustomize bases" b
bases:
  - ${1:../../base}
endsnippet

snippet kzpsm "Kustomize patch strategic merge" b
patchesStrategicMerge:
  - ${1:external_db_cfg.yaml}
endsnippet

snippet kzcpc "Kustomize components root" b
apiVersion: kustomize.config.k8s.io/v1alpha1
kind: Component

resources: 
  - ${1:external_db_cfg.yaml}
endsnippet

snippet kzcp "Kustomize components" b
components:
  - ${1:../../components/external_db}
endsnippet

snippet kzp "Kustomize patch" b
patches:
  - target:
      kind: ${1:Deployment}
      name: ${2:nginx-api}
    patch: |-
      - op: ${3:replace} # replace, delete, add
        path: ${4:/spec/replicas}
        value: ${5:10}
endsnippet

snippet 3 "Separation" b
---
endsnippet

### DOCKER

### AWS

snippet cfneks "Cloudformation EKS" b
---
Outputs:
  EksClusterEndpoint:
    Description: Eks cluster endpoint
    Value: !GetAtt EKSCluster.Endpoint
    Export:
      Name: !Sub "${AWS::StackName}-EKSCluster-Endpoint"
  Arn:
    Value: !GetAtt EKSCluster.Arn
Resources:
  myVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: ${1:10.0.0.0/16}
      EnableDnsSupport: 'true'
      EnableDnsHostnames: 'true'
      Tags:
       - Key: name
         Value: production
  mySubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      MapPublicIpOnLaunch: true
      VpcId:
        Ref: myVPC
      CidrBlock: ${2:10.0.0.0/24}
      AvailabilityZone: "${3:ap-northeast-1a"}
      Tags:
      - Key: name
        Value: production
  mySubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      MapPublicIpOnLaunch: true
      VpcId:
        Ref: myVPC
      CidrBlock: ${4:10.0.1.0/24}
      AvailabilityZone: "${5:ap-northeast-1c}"
      Tags:
      - Key: name
        Value: production
  myInternetGateway:
snippet 3 "Separation" b
___
endsnippet

### DOCKER

### AWS

snippet cfneks "Cloudformation EKS" b
---
Outputs:
  EksClusterEndpoint:
    Description: Eks cluster endpoint
    Value: !GetAtt EKSCluster.Endpoint
    Export:
      Name: !Sub "${AWS::StackName}-EKSCluster-Endpoint"
  Arn:
    Value: !GetAtt EKSCluster.Arn
Resources:
  myVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: ${1:10.0.0.0/16}
      EnableDnsSupport: 'true'
      EnableDnsHostnames: 'true'
      Tags:
       - Key: name
         Value: production
  mySubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      MapPublicIpOnLaunch: true
      VpcId:
        Ref: myVPC
      CidrBlock: ${2:10.0.0.0/24}
      AvailabilityZone: "${3:ap-northeast-1a"}
      Tags:
      - Key: name
        Value: production
  mySubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      MapPublicIpOnLaunch: true
      VpcId:
        Ref: myVPC
      CidrBlock: ${4:10.0.1.0/24}
      AvailabilityZone: "${5:ap-northeast-1c}"
      Tags:
      - Key: name
        Value: production
  myInternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
      - Key: name
        Value: production
  AttachGateway:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId:
        Ref: myVPC
      InternetGatewayId:
        Ref: myInternetGateway
  myRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId:  
        Ref: myVPC
      Tags:
      - Key: name
        Value: production
  myRoute:
    Type: AWS::EC2::Route
    DependsOn: myInternetGateway
    Properties:
       RouteTableId:
         Ref: myRouteTable
       DestinationCidrBlock: 0.0.0.0/0
       GatewayId:
         Ref: myInternetGateway
  mySubnetRouteTableAssociation1:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId:
        Ref: mySubnet1
      RouteTableId:
        Ref: myRouteTable
  mySubnetRouteTableAssociation2:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId:
        Ref: mySubnet2
      RouteTableId:
        Ref: myRouteTable
  mySG:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow http to client host
      VpcId: !Ref myVPC
      SecurityGroupIngress:
        - IpProtocol: ${6:tcp}
          FromPort: ${7:0}
          ToPort: ${8:65535}
          CidrIp: ${9:0.0.0.0/0}
      SecurityGroupEgress:
        - IpProtocol: ${10:tcp}
          FromPort: ${11:0}
          ToPort: ${12:65535}
          CidrIp: ${13:0.0.0.0/0}
  assumeRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - eks.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonEKSClusterPolicy
        - arn:aws:iam::aws:policy/AmazonEKSVPCResourceController
  EKSCluster:
    Type: AWS::EKS::Cluster
    Properties:
      Name: ${14:EKSCluster}
      Version: "${15:1.28}"
      RoleArn: !GetAtt assumeRole.Arn 
      ResourcesVpcConfig:
        SecurityGroupIds: [
          Ref: mySG
          ]
        SubnetIds: [
          Ref: mySubnet1,
          Ref: mySubnet2
          ]
  nodeGroup:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy
        - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy
        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
  EKSNodegroup:
    Type: 'AWS::EKS::Nodegroup'
    Properties: 
      ClusterName:
        Ref: EKSCluster
      NodeRole: !GetAtt nodeGroup.Arn 
      ScalingConfig:
        MinSize: ${16:3}
        DesiredSize: ${17:5}
        MaxSize: ${18:7}
      Labels:
        Key1: Value1
        Key2: Value2
      Subnets: [
        Ref: mySubnet1,
        Ref: mySubnet2
        ]
endsnippet

snippet bs "Buildspec.yml" b
version: 0.2

phases:
  install:
    commands:
      - $1
  pre_build:
    commands:
      - $2
  build:
    commands:
      - $3
  post_build:
    commands:
      - $4
artifacts:
  files:
    - $5
endsnippet

snippet circleci "CircleCI" b
version: 2.1
jobs:
  build:
    docker:
      - image: cimg/base:${1:2022.09}
        auth:
          username: $DOCKERHUB_USERNAME
          password: $DOCKERHUB_PASSWORD
    steps:
      - checkout
      - setup_remote_docker
      - restore_cache:
          keys:
            - v1-{{ .Branch }}
          paths:
            - /caches/app.tar
      - run:
          name: Load Docker image layer cache
          command: |
            set +o pipefail
            docker load -i /caches/app.tar | true
      - run:
          name: Run tests
          command: |
            docker-compose -f ./docker-compose.test.yml up
      - run:
          name: Build and Push application Docker image
          command: |
            TAG=0.1.$CIRCLE_BUILD_NUM
            docker build -t $DOCKERHUB_USERNAME/circleci-docker-example:$TAG .
            echo $DOCKERHUB_PASSWORD | docker login -u $DOCKERHUB_USERNAME --password-stdin
            docker push $DOCKERHUB_USERNAME/circleci-docker-example:$TAG
endsnippet

snippet hk3s "Hetzner k3s config file" b
---
hetzner_token: <your token>
cluster_name: test
kubeconfig_path: "./kubeconfig"
k3s_version: v1.26.4+k3s1
public_ssh_key_path: "~/.ssh/id_rsa.pub"
private_ssh_key_path: "~/.ssh/id_rsa"
use_ssh_agent: false # set to true if your key has a passphrase or if SSH connections don't work or seem to hang without agent. See https://github.com/vitobotta/hetzner-k3s#limitations
# ssh_port: 22
ssh_allowed_networks:
  - 0.0.0.0/0 # ensure your current IP is included in the range
api_allowed_networks:
  - 0.0.0.0/0 # ensure your current IP is included in the range
private_network_subnet: 10.0.0.0/16 # ensure this doesn't overlap with other networks in the same project
disable_flannel: false # set to true if you want to install a different CNI
schedule_workloads_on_masters: false
# cluster_cidr: 10.244.0.0/16 # optional: a custom IPv4/IPv6 network CIDR to use for pod IPs
# service_cidr: 10.43.0.0/16 # optional: a custom IPv4/IPv6 network CIDR to use for service IPs
# cluster_dns: 10.43.0.10 # optional: IPv4 Cluster IP for coredns service. Needs to be an address from the service_cidr range
# enable_public_net_ipv4: false # default is true
# enable_public_net_ipv6: false # default is true
# image: rocky-9 # optional: default is ubuntu-22.04
# autoscaling_image: 103908130 # optional, defaults to the `image` setting
# snapshot_os: microos # optional: specified the os type when using a custom snapshot
cloud_controller_manager_manifest_url: "https://github.com/hetznercloud/hcloud-cloud-controller-manager/releases/download/v1.18.0/ccm-networks.yaml"
csi_driver_manifest_url: "https://raw.githubusercontent.com/hetznercloud/csi-driver/v2.5.1/deploy/kubernetes/hcloud-csi.yml"
system_upgrade_controller_manifest_url: "https://raw.githubusercontent.com/rancher/system-upgrade-controller/master/manifests/system-upgrade-controller.yaml"
masters_pool:
  instance_type: cpx21
  instance_count: 3
  location: nbg1
worker_node_pools:
- name: small-static
  instance_type: cpx21
  instance_count: 4
  location: hel1
  # image: debian-11
  # labels:
  #   - key: purpose
  #     value: blah
  # taints:
  #   - key: something
  #     value: value1:NoSchedule
- name: big-autoscaled
  instance_type: cpx31
  instance_count: 2
  location: fsn1
  autoscaling:
    enabled: true
    min_instances: 0
    max_instances: 3
# additional_packages:
# - somepackage
# post_create_commands:
# - apt update
# - apt upgrade -y
# - apt autoremove -y
# enable_encryption: true
# existing_network: <specify if you want to use an existing network, otherwise one will be created for this cluster>
# kube_api_server_args:
# - arg1
# - ...
# kube_scheduler_args:
# - arg1
# - ...
# kube_controller_manager_args:
# - arg1
# - ...
# kube_cloud_controller_manager_args:
# - arg1
# - ...
# kubelet_args:
# - arg1
# - ...
# kube_proxy_args:
# - arg1
# - ...
# api_server_hostname: k8s.example.com # optional: DNS for the k8s API LoadBalancer. After the script has run, create a DNS record with the address of the API LoadBalancer.
endsnippet

snippet azdo "Azure Devops Pipeline" b
# This pipeline builds, tests, and publishes a Node.js application
trigger:
- main

pool:
  vmImage: 'ubuntu-latest'

steps:
- task: NodeTool@0
  inputs:
    versionSpec: '14.x'

- script: npm install
  displayName: 'Install dependencies'

- script: npm test
  displayName: 'Run tests'

- publish: $(System.DefaultWorkingDirectory)/dist/
  artifact: 'my-app'
  displayName: 'Publish artifact'

- condition: always()  # This step always runs, regardless of previous step results
- task: PublishBuildArtifact@1
  inputs:
    pathToPublish: '$(Build.ArtifactStagingDirectory)'
  displayName: 'Publish build artifacts'
endsnippet

snippet crppvd "Crossplane provider" b
apiVersion: pkg.crossplane.io/v1
kind: Provider
metadata:
  name: ${1:provider-aws-s3}
spec:
  package: xpkg.upbound.io/upbound/${2:provider-aws-s3}:${3:v1.1.0}
endsnippet

snippet crpcfpvd "Crossplane config provider" b
apiVersion: aws.upbound.io/v1beta1
kind: ProviderConfig
metadata:
  name: ${1:default}
spec:
  credentials:
    source: ${2:Secret}
    secretRef:
      namespace: ${3:crossplane-system}
      name: ${4:aws-secret}
      key: ${5:creds}
endsnippet

snippet crps3bk "CrossPlane S3 bucket" b
apiVersion: s3.aws.upbound.io/v1beta1
kind: Bucket
metadata:
  generateName: ${1:crossplane-bucket-}
spec:
  forProvider:
    region: ${1:ap-northeast-1}
  providerConfigRef:
    name: ${1:default}
endsnippet

snippet kedacron "KEDA cron" b
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: ${1:nginx}-scaler
  namespace: ${2:default}
spec:
  scaleTargetRef:
    name: ${3:nginx-deployment}
  minReplicaCount: ${4:1}
  cooldownPeriod: ${5:60}
  triggers:
  - type: cron
    metadata:
      timezone: ${6:Asia/Saigon}
      start: ${7:7 14 * * *}
      end: ${8:13 14 * * *}
      desiredReplicas: "${9:5}"
endsnippet

snippet csttp "OPA constraint template" b
apiVersion: templates.gatekeeper.sh/v1beta1
kind: ConstraintTemplate
metadata:
  name: ${1:nginx-min-replicas}
spec:
  crd:
    spec:
      names:
        kind: ${2:K8sMinReplicaCount}
  validation:
    # OPA rego policy definition
    openAPIV3Schema:
      properties:
        min:
          type: integer
    rego: |
      package ${3:nginx-min-replicas}

      violation[{"msg": msg}] {
        # Check if replicas are less than the minimum
        provided := input.review.object.spec.replicas
        required := input.parameters.min
        if provided < required {
          msg := sprintf("nginx deployment must have at least %v replicas", [required])
          err := hold remediation
        }
      }
endsnippet

snippet cst "OPA constraint" b
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: Constraint
metadata:
  name: ${1:nginx-deployment-min-replicas}
spec:
  match:
    kinds:
    - apiGroups: ["apps"]
      kinds: ["Deployment"]
    selector:
      matchLabels:
        app: nginx  # This selects deployments with label "app: nginx"
  parameters:
    min: ${2:4}  # Minimum required replicas for Nginx deployment
  template:
    reference:
      kind: ConstraintTemplate
      apiVersion: templates.gatekeeper.sh/v1beta1
      name: nginx-min-replicas
endsnippet

snippet semaphore "Compose file for Ansible UI" b
services:
  # uncomment this section and comment out the mysql section to use postgres instead of mysql
  #postgres:
    #restart: unless-stopped
    #image: postgres:14
    #hostname: postgres
    #volumes: 
    #  - semaphore-postgres:/var/lib/postgresql/data
    #environment:
    #  POSTGRES_USER: semaphore
    #  POSTGRES_PASSWORD: semaphore
    #  POSTGRES_DB: semaphore
  # if you wish to use postgres, comment the mysql service section below 
  mysql:
    restart: unless-stopped
    image: mysql:8.0
    hostname: mysql
    volumes:
      - semaphore-mysql:/var/lib/mysql
    environment:
      MYSQL_RANDOM_ROOT_PASSWORD: 'yes'
      MYSQL_DATABASE: semaphore
      MYSQL_USER: semaphore
      MYSQL_PASSWORD: semaphore
  semaphore:
    restart: unless-stopped
    ports:
      - 3000:3000
    image: semaphoreui/semaphore:latest
    environment:
      SEMAPHORE_DB_USER: semaphore
      SEMAPHORE_DB_PASS: semaphore
      SEMAPHORE_DB_HOST: mysql # for postgres, change to: postgres
      SEMAPHORE_DB_PORT: 3306 # change to 5432 for postgres
      SEMAPHORE_DB_DIALECT: mysql # for postgres, change to: postgres
      SEMAPHORE_DB: semaphore
      SEMAPHORE_PLAYBOOK_PATH: /tmp/semaphore/
      SEMAPHORE_ADMIN_PASSWORD: changeme
      SEMAPHORE_ADMIN_NAME: admin
      SEMAPHORE_ADMIN_EMAIL: admin@localhost
      SEMAPHORE_ADMIN: admin
      SEMAPHORE_ACCESS_KEY_ENCRYPTION: gs72mPntFATGJs9qK0pQ0rKtfidlexiMjYCH9gWKhTU=
      SEMAPHORE_LDAP_ACTIVATED: 'no' # if you wish to use ldap, set to: 'yes' 
      SEMAPHORE_LDAP_HOST: dc01.local.example.com
      SEMAPHORE_LDAP_PORT: '636'
      SEMAPHORE_LDAP_NEEDTLS: 'yes'
      SEMAPHORE_LDAP_DN_BIND: 'uid=bind_user,cn=users,cn=accounts,dc=local,dc=shiftsystems,dc=net'
      SEMAPHORE_LDAP_PASSWORD: 'ldap_bind_account_password'
      SEMAPHORE_LDAP_DN_SEARCH: 'dc=local,dc=example,dc=com'
      SEMAPHORE_LDAP_SEARCH_FILTER: "(\u0026(uid=%s)(memberOf=cn=ipausers,cn=groups,cn=accounts,dc=local,dc=example,dc=com))"
    depends_on:
      - mysql # for postgres, change to: postgres
volumes:
  semaphore-mysql: # to use postgres, switch to: semaphore-postgres
endsnippet

snippet kafka "Kafka implemented in container" b
version: "3.7"
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:5.5.3
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-enterprise-kafka:5.5.3
    depends_on:
      - zookeeper

    ports:
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT


  debezium:
    image: debezium/connect:1.4
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
    depends_on: [kafka]
    ports:
      - 8083:8083

  schema-registry:
    image: confluentinc/cp-schema-registry:5.5.3
    environment:
      - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
      - SCHEMA_REGISTRY_HOST_NAME=schema-registry
      - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8081,http://localhost:8081
    ports:
      - 8081:8081
    depends_on: [zookeeper, kafka]
  
  kafka_manager:
    image: hlebalbau/kafka-manager:stable
    restart: always
    ports:
      - "9000:9000"
    depends_on:
      - zookeeper
      - kafka
    environment:
      ZK_HOSTS: "zookeeper:2181"
      APPLICATION_SECRET: "random-secret"
    command: -Dpidfile.path=/dev/null 
endsnippet

snippet matchexpress "Match expression json form in yaml" b
matchExpressions:
- { key: serviceMonitorSelector, operator: In, values: [prometheus, app1, app2] }
endsnippet

snippet matexp "Match expression yaml form" b
matchExpressions:
- key: serviceMonitorSelector
  operator: In
  values: 
  - prometheus
  - app1
  - app2
endsnippet

snippet promrule "Prometheus rules" b
  - alert: PrometheusJobMissing
    expr: absent(up{job="prometheus"})
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: Prometheus job missing (instance {{ $labels.instance }})
      description: "A Prometheus job has disappeared\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
endsnippet

snippet prometheusrule "Prometheus rule full yaml file" b
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: mysql-exporter-prometheus-rules
  namespace: mysql-exporter
spec:
  groups:
  - name: mysql-exporter
    rules: 
    - alert: MySQLStorageRunningOut
      expr: 
      for: 30s
      labels:
        severity: warning
      annotations:
        description: DB is run out of storage for 30 seconds
        summary: DB run out of storage
        type: Container
endsnippet

snippet argobootstrap "ArgoCD Bootstrap" b
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  labels:
    app.kubernetes.io/managed-by: helm
    app.kubernetes.io/name: argo-cd
  name: bootstrap
  namespace: argo-cd
  finalizers:
  - resources-finalizer.argocd.argoproj.io
spec:
  project: default
  destination:
    namespace: argo-cd
    server: https://kubernetes.default.svc
  ignoreDifferences:
  - group: argoproj.io
    jsonPointers:
    - /status
    kind: Application
  source:
    path: ${2:aio}
    repoURL: ${1:Repository-URL}
    targetRevision: main
  syncPolicy:
      automated:
        prune: true
        selfHeal: true
      syncOptions:
        - ApplyOutOfSyncOnly=true
        - PruneLast=true
        - CreateNamespace=true
        - Validate=false
endsnippet

snippet argoaio "ArgoCD app all in one" b
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ${1:<environment>-<application>}
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  project: ${2:<project>}
  source:
    repoURL: {{ .Values.spec.source.repoURL }}
    targetRevision: {{ .Values.spec.source.targetRevision }}
    path: apps/ghsv-v2-push-notification
    helm:
      valueFiles:
        - ${3:values-dev.yaml}
  destination:
    server: {{ .Values.spec.destination.server }}
    namespace: ${4:development}
  syncPolicy:
    syncOptions:
      - ApplyOutOfSyncOnly=true
      - PruneLast=true
      - CreateNamespace=true
      - Validate=false
endsnippet

snippet argoaiovalue "ArgoCD all in one helm values" b
spec:
  project: ${1:<project>} # project name
  destination:
    server: https://kubernetes.default.svc
    namespace: ${2:argocd} # namespace name
  source:
    repoURL: ${3:Repository-URL} # repository url
    targetRevision: ${4:main} # branch name or commit hash
endsnippet

snippet ansibleecho "Ansible playbook echo hello world [ test only ]" b
---
- name: Echo Hello World on all instances
  hosts: all
  tasks:
    - name: Echo Hello World
      command: echo "Instance is running ?"
endsnippet

snippet dockercompose "Sample docker compose" b
version: '3'
services:
  ${1:certificate_check}:
    build:
      context: .
      dockerfile: Dockerfile
endsnippet

snippet mongo "Docker compose mongo" b
  mongo:
    image: mongo
    networks:
      - external_network
    env_file: .env
    restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: 'root'
      MONGO_INITDB_ROOT_PASSWORD: 'secret'
    ports:
      - 27017:27017
endsnippet

snippet mongoclientonk8s "Mongo Client on kubernetes" b
apiVersion: v1
kind: Pod
metadata:
  name: mongodb-client
  labels:
    app: mongo-client
spec:
  containers:
  - name: mongodb-client
    image: mongo:latest  # You can use the MongoDB image version you need
    command: [ "sleep", "3600" ]  # Keep the pod running
    env:
    - name: MONGO_URI
      valueFrom:
        secretKeyRef:
          name: mongodb-exporter-secrets 
          key: mongodb-uri
    ports:
    - containerPort: 27017
      name: mongo
  restartPolicy: Never
endsnippet
